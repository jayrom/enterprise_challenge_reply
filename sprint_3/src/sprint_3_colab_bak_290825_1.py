# -*- coding: utf-8 -*-
"""FIAP - Reply - Enterprise Challenge - SIMP - Sistema Inteligente de Manutenção Preditiva - Sprint 3

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/jayrom/enterprise_challenge_reply/blob/main/sprint_3/src/exploratory.ipynb

# Análise de modelagem para manutenção preditiva

## Importar módulos
"""

import warnings
warnings.filterwarnings('ignore')
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import missingno as msno

"""## Dataset

### Carregar dataset
"""

df = pd.read_csv("simulated_sensor_data.csv")

"""### Converter timestamp"""

# Converter a coluna 'timestamp' para o tipo datetime para facilitar a análise
df['timestamp'] = pd.to_datetime(df['timestamp'])

"""### Exibir dataset head"""

df.head()

"""### Exibir informações sobre o dataset"""

df.info()

"""### Exibir estatísticas básicas do dataframe original"""

df.describe()

"""## Limpeza dos dados

### Verificar dados faltantes
"""

import missingno as msno
msno.matrix(df);

"""### Verificar dados duplicados"""

duplicates = df.duplicated().sum()
print("Número de dados duplicados:", duplicates)

"""Remover duplicatas, se houver"""

df = df.drop_duplicates()

"""## Investigar outliers"""

plt.figure(figsize=(12, 6))
sns.boxplot(data=df)
plt.title("Boxplot para detectar outliers")
plt.xticks(rotation=45)
plt.show()

"""#### Análise gráfica dos outliers"""

# Criar uma figura e eixos para os gráficos
fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(15, 12), sharex=True)

# Plotar os dados para o motor_1
axes[0].plot(df[df['device_id'] == 'motor_1']['timestamp'], df[df['device_id'] == 'motor_1']['vibration_rms_g'], label='Motor 1', color='red')
axes[1].plot(df[df['device_id'] == 'motor_1']['timestamp'], df[df['device_id'] == 'motor_1']['temperature_c'], color='red')
axes[2].plot(df[df['device_id'] == 'motor_1']['timestamp'], df[df['device_id'] == 'motor_1']['current_amps'], color='red')

# Plotar os dados para o motor_2 (linha de base)
axes[0].plot(df[df['device_id'] == 'motor_2']['timestamp'], df[df['device_id'] == 'motor_2']['vibration_rms_g'], label='Motor 2', color='blue')
axes[1].plot(df[df['device_id'] == 'motor_2']['timestamp'], df[df['device_id'] == 'motor_2']['temperature_c'], color='blue')
axes[2].plot(df[df['device_id'] == 'motor_2']['timestamp'], df[df['device_id'] == 'motor_2']['current_amps'], color='blue')

# Adicionar títulos e rótulos
axes[0].set_title('Vibração (Vibration_rms_g)')
axes[1].set_title('Temperatura (Temperature_c)')
axes[2].set_title('Corrente (Current_amps)')
axes[2].set_xlabel('Timestamp')
axes[0].set_ylabel('Vibração (g)')
axes[1].set_ylabel('Temperatura (°C)')
axes[2].set_ylabel('Corrente (A)')
fig.suptitle('Comportamento dos Sensores ao Longo do Tempo', fontsize=16)

# Adicionar uma legenda e exibir o gráfico
fig.legend(loc='upper right')
plt.tight_layout(rect=[0, 0, 1, 0.96]) # Ajusta o layout para evitar sobreposição do título
plt.show()

"""Investigar correlação entre outliers e falha"""

# Cópia do DataFrame original
df_plot = df.copy()

# Crie uma coluna 'status' para facilitar a visualização
df_plot['status'] = 'Normal'
df_plot.loc[df_plot['days_to_failure'] != -1, 'status'] = 'Em Falha'

# Filtrar o DataFrame apenas para o Motor 1, que é o que falhou
df_motor1 = df_plot[df_plot['device_id'] == 'motor_1']

# Criar uma figura e eixos para os gráficos
fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(15, 12), sharex=True)

# Definir as cores com base no status
colors = df_motor1['status'].map({'Normal': 'blue', 'Em Falha': 'red'})

# Plotar os dados do Motor 1, colorindo por status
axes[0].scatter(df_motor1['timestamp'], df_motor1['vibration_rms_g'], c=colors, s=5)
axes[1].scatter(df_motor1['timestamp'], df_motor1['temperature_c'], c=colors, s=5)
axes[2].scatter(df_motor1['timestamp'], df_motor1['current_amps'], c=colors, s=5)

# Adicionar rótulos e títulos
axes[0].set_title('Vibração (Vibration_rms_g) - Motor 1')
axes[1].set_title('Temperatura (Temperature_c) - Motor 1')
axes[2].set_title('Corrente (Current_amps) - Motor 1')
axes[2].set_xlabel('Timestamp')
axes[0].set_ylabel('Vibração (g)')
axes[1].set_ylabel('Temperatura (°C)')
axes[2].set_ylabel('Corrente (A)')
fig.suptitle('Anomalias (Outliers) Correlacionadas com a Falha', fontsize=16)

# Criar uma legenda manual
from matplotlib.lines import Line2D
legend_elements = [
    Line2D([0], [0], marker='o', color='w', label='Normal', markerfacecolor='blue', markersize=8),
    Line2D([0], [0], marker='o', color='w', label='Em Falha', markerfacecolor='red', markersize=8)
]
axes[0].legend(handles=legend_elements, loc='upper left')

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

"""Plot dos dados sem falhas"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Filtrar o DataFrame para os primeiros 30 dias de dados
df_first_30_days = df[df['days_to_failure'] == -1]

# Você também pode fazer isso por data, caso não tenha a coluna days_to_failure
# start_date = df['timestamp'].min()
# end_date = start_date + pd.Timedelta(days=30)
# df_first_30_days = df[(df['timestamp'] >= start_date) & (df['timestamp'] < end_date)]


# Boxplot dos dados filtrados
plt.figure(figsize=(12, 6))

# Filtrar variáveis de dados dos sensores
columns_to_plot = ['temperature_c', 'current_amps', 'vibration_rms_g']
sns.boxplot(data=df_first_30_days[columns_to_plot])
plt.title("Boxplot dos Primeiros 30 Dias (Sem Falha)")
plt.xticks(rotation=45)
plt.show()

"""### Correlação entre as variáveis"""

# Variáveis de interesse
sensor_data = df[['temperature_c', 'current_amps', 'vibration_rms_g']]

# Matriz de correlação
correlation_matrix = sensor_data.corr()

# Heatmap para visualizar a correlação
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f",
            linewidths=.5, cbar_kws={'label': 'Coeficiente de Correlação'})

plt.title('Heatmap da Matriz de Correlação dos Sensores')
plt.show()

"""## Modelagem

### Importar módulos
"""

# Modelos de Regressão
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Modelos de Classificação
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Módulos de pré-processamento
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
import seaborn as sns
import matplotlib.pyplot as plt

"""### Codificação"""

# Codificação da variável categórica 'device_id' com get_dummies
df_encoded = pd.get_dummies(df, columns=['device_id'], prefix='device')
df_encoded

"""### Features e pré-processamento"""

# Indicar features
features_encoded = ['temperature_c', 'current_amps', 'vibration_rms_g', 'device_motor_1', 'device_motor_2']
X = df_encoded[features_encoded]
y_reg = df_encoded['days_to_failure']

# Pré-processamento e normalização das features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

"""## Modelos de regressão<br /><sub>(predição da vida útil restante)</sub>"""

y_reg = df['days_to_failure']

# Separar dados de treino e teste
X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_scaled, y_reg, test_size=0.3, random_state=42)

"""### Regressão linear"""

# Treinamento
print("\nTreinando Regressão Linear")
lr_model = LinearRegression()
lr_model.fit(X_train_reg, y_train_reg)
y_pred_lr = lr_model.predict(X_test_reg)

# Avaliação
print("\nAvaliação do modelo de Regressão Linear")
mse_lr = mean_squared_error(y_test_reg, y_pred_lr)
r2_lr = r2_score(y_test_reg, y_pred_lr)
print(f"MSE (Erro Quadrático Médio) - Regressão Linear: {mse_lr:.2f}")
print(f"R² (Coeficiente de Determinação) - Regressão Linear: {r2_lr:.2f}")

"""### Regressão Random Forest"""

# Treinamento
print("\nTreinando Random Forest Regressor")
rf_reg_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_reg_model.fit(X_train_reg, y_train_reg)
y_pred_rf_reg = rf_reg_model.predict(X_test_reg)

# Avaliação
mse_rf = mean_squared_error(y_test_reg, y_pred_rf_reg)
r2_rf = r2_score(y_test_reg, y_pred_rf_reg)
print(f"MSE (Erro Quadrático Médio) - Random Forest: {mse_rf:.2f}")
print(f"R² (Coeficiente de Determinação) - Random Forest: {r2_rf:.2f}")

"""## Modelos de classificação<br /><sub>(detecção de falha)</sub>"""

# Codificar 'failure_mode'
le = LabelEncoder()
y_class = df_encoded['failure_mode']

# Separar dados de treino e teste
X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_scaled, y_class, test_size=0.3, random_state=42)

"""### Regressão Logística"""

# Treinamento
print("\nTreinando Regressão Logística")
log_reg_model = LogisticRegression(random_state=42)
log_reg_model.fit(X_train_class, y_train_class)
y_pred_log_reg = log_reg_model.predict(X_test_class)

# Avaliação
accuracy_log_reg = accuracy_score(y_test_class, y_pred_log_reg)
print(f"Acurácia - Regressão Logística: {accuracy_log_reg:.2f}")
print("\nRelatório de Classificação:")
print(classification_report(y_test_class, y_pred_log_reg, target_names=df['failure_mode'].unique()))
# O target_names usa os rótulos originais para melhor legibilidade do relatório

"""### Support Vector Machine (SVM)"""

# Treinamento
print("\nTreinando SVM")
svm_model = SVC(kernel='linear', random_state=42)
svm_model.fit(X_train_class, y_train_class)
y_pred_svm = svm_model.predict(X_test_class)

# Avaliação
accuracy_svm = accuracy_score(y_test_class, y_pred_svm)
print(f"Acurácia - SVM: {accuracy_svm:.2f}")
print("\nRelatório de Classificação:")
print(classification_report(y_test_class, y_pred_svm, target_names=df['failure_mode'].unique()))

"""## Uso dos modelos"""

# -> Exemplo de como usar o modelo treinado
print("\n-> Exemplo de como usar o modelo treinado")
import numpy as np
# Dados de um novo ponto do motor em falha (valores elevados)
new_data_point = np.array([[55.0, 7.5, 0.8, True, False]]) # Added device_motor_1 and device_motor_2 features
new_data_point_scaled = scaler.transform(new_data_point)

# Predição de Regressão (Random Forest)
predicted_days_to_failure = rf_reg_model.predict(new_data_point_scaled)
print(f"Vida Útil Restante (RF Regressor): Aproximadamente {predicted_days_to_failure[0]:.2f} dias")

# Predição de Classificação (Regressão Logística)
predicted_class = log_reg_model.predict(new_data_point_scaled)
predicted_label = predicted_class # The prediction is already a string in this case
print(f"Classificação (Regressão Logística): O estado do motor é '{predicted_label[0]}'")