# -*- coding: utf-8 -*-
"""FIAP - Reply - Enterprise Challenge - SIMP - Sistema Inteligente de Manutenção Preditiva - Sprint 4

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/jayrom/fiap_exercises_gen/blob/main/reply_test/src/reply_4_app.ipynb

# Análise de modelagem para manutenção preditiva

## Importar módulos
"""

import warnings
warnings.filterwarnings('ignore')
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import missingno as msno
from joblib import dump, load

"""## Dataset

### Carregar dataset
"""

df = pd.read_csv("train_simulated_sensor_data.csv")

"""### Converter timestamp"""

# Converter a coluna 'timestamp' para o tipo datetime para facilitar a análise
df['timestamp'] = pd.to_datetime(df['timestamp'])

"""### Exibir dataset head"""

df.head()

"""### Exibir informações sobre o dataset"""

df.info()

"""### Exibir estatísticas básicas do dataframe original"""

df.describe()

"""## Limpeza dos dados

### Verificar dados faltantes
"""

import missingno as msno
msno.matrix(df);

"""### Verificar dados duplicados"""

duplicates = df.duplicated().sum()
print("Número de dados duplicados:", duplicates)

"""Remover duplicatas, se houver"""

df = df.drop_duplicates()

"""## Investigar outliers"""

plt.figure(figsize=(12, 6))
sns.boxplot(data=df)
plt.title("Boxplot para detectar outliers")
plt.xticks(rotation=45)
plt.show()

"""#### Análise gráfica dos outliers"""

# Criar uma figura e eixos para os gráficos
fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(15, 12), sharex=True)

# Plotar os dados para o motor_1
axes[0].plot(df[df['device_id'] == 'motor_A']['timestamp'], df[df['device_id'] == 'motor_A']['vibration_magnitude_mss'], label='Motor A', color='red')
axes[1].plot(df[df['device_id'] == 'motor_A']['timestamp'], df[df['device_id'] == 'motor_A']['temperature_c'], color='red')
axes[2].plot(df[df['device_id'] == 'motor_A']['timestamp'], df[df['device_id'] == 'motor_A']['current_amps'], color='red')

# Plotar os dados para o motor_2 (linha de base)
axes[0].plot(df[df['device_id'] == 'motor_B']['timestamp'], df[df['device_id'] == 'motor_B']['vibration_magnitude_mss'], label='Motor B', color='blue')
axes[1].plot(df[df['device_id'] == 'motor_B']['timestamp'], df[df['device_id'] == 'motor_B']['temperature_c'], color='blue')
axes[2].plot(df[df['device_id'] == 'motor_B']['timestamp'], df[df['device_id'] == 'motor_B']['current_amps'], color='blue')

# Adicionar títulos e rótulos
axes[0].set_title('Vibração (Vibration_magnitude_mss)')
axes[1].set_title('Temperatura (Temperature_c)')
axes[2].set_title('Corrente (Current_amps)')
axes[2].set_xlabel('Timestamp')
axes[0].set_ylabel('Vibração (mss)')
axes[1].set_ylabel('Temperatura (°C)')
axes[2].set_ylabel('Corrente (A)')
fig.suptitle('Comportamento dos Sensores ao Longo do Tempo', fontsize=16)

# Adicionar uma legenda e exibir o gráfico
fig.legend(loc='upper right')
plt.tight_layout(rect=[0, 0, 1, 0.96]) # Ajusta o layout para evitar sobreposição do título
plt.show()

"""Investigar correlação entre outliers e falha

##### *Motor A*
"""

# Cópia do DataFrame original
df_plot = df.copy()

# Adicionar coluna 'status' para legenda
df_plot['status'] = 'Normal'
df_plot.loc[df_plot['days_to_failure'] != -1, 'status'] = 'Em Falha'

# Filtrar o DataFrame para o Motor A (o que falhou)
df_motorA = df_plot[df_plot['device_id'] == 'motor_A']

# Criar figura para os gráficos
fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(15, 12), sharex=True)

# Definir as cores com base no status
colors = df_motorA['status'].map({'Normal': 'black', 'Em Falha': 'orange'})

# Plotar os dados do Motor 1, colorindo por status
axes[0].scatter(df_motorA['timestamp'], df_motorA['vibration_magnitude_mss'], c=colors, s=5)
axes[1].scatter(df_motorA['timestamp'], df_motorA['temperature_c'], c=colors, s=5)
axes[2].scatter(df_motorA['timestamp'], df_motorA['current_amps'], c=colors, s=5)

# Adicionar rótulos e títulos
axes[0].set_title('Vibração (Vibration_magnitude_mss) - Motor A')
axes[1].set_title('Temperatura (Temperature_c) - Motor A')
axes[2].set_title('Corrente (Current_amps) - Motor A')
axes[2].set_xlabel('Timestamp')
axes[0].set_ylabel('Vibração (mss)')
axes[1].set_ylabel('Temperatura (°C)')
axes[2].set_ylabel('Corrente (A)')
fig.suptitle('Anomalias (outliers) correlacionadas com a falha', fontsize=16)

# Legenda
from matplotlib.lines import Line2D
legend_elements = [
    Line2D([0], [0], marker='o', color='w', label='Normal', markerfacecolor='green', markersize=8),
    Line2D([0], [0], marker='o', color='w', label='Em Falha', markerfacecolor='purple', markersize=8)
]
axes[0].legend(handles=legend_elements, loc='upper left')

plt.tight_layout(rect=[0, 0, 1, 0.96])
plt.show()

"""Plot dos dados sem falhas"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Filtrar o DataFrame para os primeiros 30 dias de dados
df_first_30_days = df[df['days_to_failure'] == -1]

# start_date = df['timestamp'].min()
# end_date = start_date + pd.Timedelta(days=30)
# df_first_30_days = df[(df['timestamp'] >= start_date) & (df['timestamp'] < end_date)]


# Boxplot dos dados filtrados
plt.figure(figsize=(12, 6))

# Filtrar variáveis de dados dos sensores
columns_to_plot = ['temperature_c', 'current_amps', 'vibration_magnitude_mss']
sns.boxplot(data=df_first_30_days[columns_to_plot])
plt.title("Boxplot dos Primeiros 30 Dias (Sem Falha)")
plt.xticks(rotation=45)
plt.show()

"""### Correlação entre as variáveis"""

# Variáveis de interesse
sensor_data = df[['temperature_c', 'current_amps', 'vibration_magnitude_mss']]

# Matriz de correlação
correlation_matrix = sensor_data.corr()

# Heatmap da correlação
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f",
            linewidths=.5, cbar_kws={'label': 'Coeficiente de Correlação'})

plt.title('Heatmap da matriz de correlação dos sensores')
plt.show()

"""## Modelagem

### Importar módulos
"""

# Modelos de Regressão
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Modelos de Classificação
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Módulos de pré-processamento
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
import seaborn as sns
import matplotlib.pyplot as plt

"""### Codificação"""

# Codificação da variável categórica 'device_id'
df_encoded = pd.get_dummies(df, columns=['device_id'], prefix='device')
df_encoded

"""### Features e pré-processamento"""

# Indicar features
features_encoded = ['temperature_c', 'current_amps', 'vibration_magnitude_mss', 'device_motor_A', 'device_motor_B']
X = df_encoded[features_encoded]
y_reg = df_encoded['days_to_failure']

# Pré-processamento e normalização das features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Exportar o scaler para uso em preições posteriores
dump(scaler, 'scaler.joblib')

"""## Modelos de regressão<br /><sub>(predição da vida útil restante)</sub>"""

y_reg = df['days_to_failure']

# Dados de treino e teste
X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_scaled, y_reg, test_size=0.3, random_state=42)

"""### Regressão linear"""

# Treinamento
print("\nTreinando Regressão Linear")
lr_model = LinearRegression()
lr_model.fit(X_train_reg, y_train_reg)
y_pred_lr = lr_model.predict(X_test_reg)

# Avaliação
print("\nAvaliação do modelo de Regressão Linear")
mse_lr = mean_squared_error(y_test_reg, y_pred_lr)
r2_lr = r2_score(y_test_reg, y_pred_lr)
print(f"MSE (Erro Quadrático Médio) - Regressão Linear: {mse_lr:.2f}")
print(f"R² (Coeficiente de Determinação) - Regressão Linear: {r2_lr:.2f}")

# Salvar o modelo treinado
dump(lr_model, 'linear_regression_model.joblib')

"""### Regressão Random Forest"""

# Treinamento
print("\nTreinando Random Forest Regressor")
rf_reg_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_reg_model.fit(X_train_reg, y_train_reg)
y_pred_rf_reg = rf_reg_model.predict(X_test_reg)

# Avaliação
mse_rf = mean_squared_error(y_test_reg, y_pred_rf_reg)
r2_rf = r2_score(y_test_reg, y_pred_rf_reg)
print(f"MSE (Erro Quadrático Médio) - Random Forest: {mse_rf:.2f}")
print(f"R² (Coeficiente de Determinação) - Random Forest: {r2_rf:.2f}")

# Salvar o modelo treinado
dump(rf_reg_model, 'random_forest_regressor_model.joblib')

"""## Modelos de classificação<br /><sub>(detecção de falha)</sub>"""

# Codificar 'failure_mode'
le = LabelEncoder()
y_class = le.fit_transform(df_encoded['failure_mode'])

# Dados de treino e teste
X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_scaled, y_class, test_size=0.3, random_state=42)

# Salvar o LabelEncoder, para converter predições numéricas de volta para texto
dump(le, 'label_encoder.joblib')

"""### Regressão Logística"""

# Treinamento
print("\nTreinando Regressão Logística")
log_reg_model = LogisticRegression(random_state=42)
log_reg_model.fit(X_train_class, y_train_class)
y_pred_log_reg = log_reg_model.predict(X_test_class)

# Avaliação
accuracy_log_reg = accuracy_score(y_test_class, y_pred_log_reg)
print(f"Acurácia - Regressão Logística: {accuracy_log_reg:.2f}")
print("\nRelatório de Classificação:")
print(classification_report(y_test_class, y_pred_log_reg, target_names=df['failure_mode'].unique()))

# Matriz de Confusão
cm_log_reg = confusion_matrix(y_test_class, y_pred_log_reg)
print("\nMatriz de Confusão - Regressão Logística:")
print(cm_log_reg)

# Heatmap da Matriz de Confusão
plt.figure(figsize=(8, 6))
sns.heatmap(cm_log_reg, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)
plt.title('Matriz de Confusão - Regressão Logística')
plt.ylabel('Valores Reais')
plt.xlabel('Valores Previstos')
plt.show()

# Salvar o modelo treinado
dump(log_reg_model, 'logistic_regression_model.joblib')

"""### Support Vector Machine (SVM)"""

# Treinamento
print("\nTreinando SVM")
svm_model = SVC(kernel='linear', random_state=42)
svm_model.fit(X_train_class, y_train_class)
y_pred_svm = svm_model.predict(X_test_class)

# Avaliação
accuracy_svm = accuracy_score(y_test_class, y_pred_svm)
print(f"Acurácia - SVM: {accuracy_svm:.2f}")
print("\nRelatório de Classificação:")
print(classification_report(y_test_class, y_pred_svm, target_names=df['failure_mode'].unique()))

# Matriz de confusão
cm_svm = confusion_matrix(y_test_class, y_pred_svm)
print("\nMatriz de Confusão - SVM:")
print(cm_svm)

# Heatmap da matriz de confusão
plt.figure(figsize=(8, 6))
sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)
plt.title('Matriz de Confusão - SVM')
plt.ylabel('Valores Reais')
plt.xlabel('Valores Previstos')
plt.show()

# Salvar o modelo treinado
dump(svm_model, 'svm_model.joblib')

"""## Uso dos modelos"""

# Exemplo uso do modelo treinado
print("\nExemplo uso do modelo treinado")
import numpy as np

# Dados de um novo ponto do motor em falha (valores elevados)
new_data_point = np.array([[55.0, 7.5, 0.8, True, False]]) # Added device_motor_1 and device_motor_2 features
new_data_point_scaled = scaler.transform(new_data_point)

print(f"Dados puros: {new_data_point}")

print(f"\nDados de leitura")
print("----------------\n")

new_data_point_scaled[0][0] = round(new_data_point_scaled[0][0], 2)
new_data_point_scaled[0][1] = round(new_data_point_scaled[0][1], 2)
new_data_point_scaled[0][2] = round(new_data_point_scaled[0][2], 2)

print(f"Temperatura: {new_data_point[0][0]} °C")
print(f"Corrente: {new_data_point[0][1]} A")
print(f"Vibração: {new_data_point[0][2]} g")

device = "motor_A" if new_data_point[0][3] else "motor_B"
print(f"Dispositivo: {device}\n")

print(f"Dados padronizados: {new_data_point_scaled}\n")


print(f"\nPredições")
print("---------\n")


# Predição de Regressão (Random Forest)
predicted_days_to_failure = rf_reg_model.predict(new_data_point_scaled)
print(f"Vida Útil Restante (RF Regressor): Aproximadamente {predicted_days_to_failure[0]:.2f} dias")

# Predição de Classificação (Regressão Logística)
predicted_class = log_reg_model.predict(new_data_point_scaled)
predicted_label = predicted_class # The prediction is already a string in this case

status = "normal" if predicted_label[0] == 0 else "em falha"
print(f"Classificação (Regressão Logística): O estado do motor é '{status}'")